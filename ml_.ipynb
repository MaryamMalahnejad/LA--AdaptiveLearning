{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaryamMalahnejad/LA--AdaptiveLearning/blob/mta%2Fbackend/ml_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk8nzRKSviDP",
        "outputId": "f5e0a982-0425-4bd2-b562-bdda68c30d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-30 18:18:27,245 INFO sqlalchemy.engine.Engine SELECT CAST(SERVERPROPERTY('ProductVersion') AS VARCHAR)\n",
            "2024-01-30 18:18:27,246 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
            "2024-01-30 18:18:27,271 INFO sqlalchemy.engine.Engine SELECT schema_name()\n",
            "2024-01-30 18:18:27,271 INFO sqlalchemy.engine.Engine [generated in 0.00082s] ()\n",
            "2024-01-30 18:18:27,332 INFO sqlalchemy.engine.Engine SELECT CAST('test max support' AS NVARCHAR(max))\n",
            "2024-01-30 18:18:27,332 INFO sqlalchemy.engine.Engine [generated in 0.00054s] ()\n",
            "2024-01-30 18:18:27,363 INFO sqlalchemy.engine.Engine SELECT 1 FROM fn_listextendedproperty(default, default, default, default, default, default, default)\n",
            "2024-01-30 18:18:27,363 INFO sqlalchemy.engine.Engine [generated in 0.00049s] ()\n",
            "Connection successful !!!!\n",
            "2024-01-30 18:18:27,408 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
            "2024-01-30 18:18:27,408 INFO sqlalchemy.engine.Engine SELECT * FROM import_extra_intiger;\n",
            "2024-01-30 18:18:27,408 INFO sqlalchemy.engine.Engine [generated in 0.00075s] ()\n",
            "!!! df retrieved values:     id  effectiveness  trust  openness  typee  style  loudness  sessions  \\\n",
            "0    1              1      2         1      1      2         1         1   \n",
            "1   10              2      4         4      2      3         2         2   \n",
            "2   11              2      3         3      4      2         1         2   \n",
            "3   12              2      3         3      1      2         2         2   \n",
            "4   13              2      3         2      1      2         2         2   \n",
            "..  ..            ...    ...       ...    ...    ...       ...       ...   \n",
            "68  71              3      3         3      4      2         2         2   \n",
            "69  72              2      3         3      1      2         1         1   \n",
            "70  73              2      3         3      1      3         1         2   \n",
            "71   8              2      3         4      4      1         1         1   \n",
            "72   9              2      3         4      2      1         2         2   \n",
            "\n",
            "    dig_tra on_in  student_id  study_help  \n",
            "0         2     2         147           1  \n",
            "1         2     1         156           1  \n",
            "2         2     2         157           5  \n",
            "3         2     2         158           5  \n",
            "4         1     2         159           5  \n",
            "..      ...   ...         ...         ...  \n",
            "68        2     2         217           6  \n",
            "69        1     2         218           2  \n",
            "70        2     2         219           1  \n",
            "71        2     2         154           3  \n",
            "72        2     2         155           2  \n",
            "\n",
            "[73 rows x 12 columns]\n",
            "Model Accuracy: 53.33%\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import urllib.parse\n",
        "# Load your dataset\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "\n",
        "# Load your dataset\n",
        "params = urllib.parse.quote_plus(r'Driver={ODBC Driver 18 for SQL Server};Server=tcp:adaptive-learning-server.database.windows.net,1433;Database=adaptive_learning_db;Uid=superadmin;Pwd=Poorpassword@2024;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;')\n",
        "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
        "engine_azure = create_engine(conn_str,echo=True)\n",
        "\n",
        "connection = engine_azure.connect()\n",
        "print(\"Connection successful !!!!\")\n",
        "\n",
        "# Perform a query to fetch effectivness\n",
        "query = text(\n",
        "    \"SELECT * \"\n",
        "    \"FROM import_extra_intiger;\"\n",
        ")\n",
        "\n",
        "result = connection.execute(query)\n",
        "\n",
        "# Fetch all the rows and convert them to a Pandas DataFrame\n",
        "df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
        "print(\"!!! df retrieved values:\", df)\n",
        "# Assuming your data is stored in a variable named 'df'\n",
        "# Replace 'style' with the target variable you want to predict\n",
        "X = df.drop('style', axis=1)\n",
        "y = df['style']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier (you can choose a different algorithm based on your needs)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afGICtBgwRfI",
        "outputId": "0256c625-d32a-46fa-c13a-965e474d00b5"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Audiobooks\n- Auditory_Materials\n- Collaborative\n- Collaborative_Materials\n- Diagrams_and_Charts\n- ...\nFeature names seen at fit time, yet now missing:\n- student_id\n- study_help\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m new_user_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([new_user_data])\n\u001b[1;32m     55\u001b[0m \u001b[39m# Assuming your model is named 'model' and is already trained\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# Use the model to predict the learning style for the new user\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m predicted_learning_style \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(new_user_df)\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredicted Learning Style for the New User: \u001b[39m\u001b[39m{\u001b[39;00mpredicted_learning_style[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
            "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Audiobooks\n- Auditory_Materials\n- Collaborative\n- Collaborative_Materials\n- Diagrams_and_Charts\n- ...\nFeature names seen at fit time, yet now missing:\n- student_id\n- study_help\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "query = text(\n",
        "    \"SELECT * \"\n",
        "    \"FROM user_input_data_integer;\"\n",
        ")\n",
        "\n",
        "result = connection.execute(query)\n",
        "\n",
        "# Fetch all the rows and convert them to a Pandas DataFrame\n",
        "df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
        "print(\"!!! df retrieved values:\", df)\n",
        "\n",
        "# Assumed data for a new user\n",
        "new_user_data = {\n",
        "    'age': 25,\n",
        "    'gender': 1,  # Assuming 1 for Male, 2 for Female\n",
        "    'study_field': 3,  # Assuming a specific field code\n",
        "    'education_level': 2,  # Assuming 1 for High School, 2 for College, etc.\n",
        "    'employment_status': 1,  # Assuming 0 for Unemployed, 1 for Employed\n",
        "    'study_place': 2,  # Assuming 1 for Home, 2 for Library, etc.\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "new_user_df = pd.DataFrame([new_user_data])\n",
        "\n",
        "# Assuming your model is named 'model' and is already trained\n",
        "# Use the model to predict the learning style for the new user\n",
        "predicted_learning_style = model.predict(new_user_df)\n",
        "\n",
        "print(f'Predicted Learning Style for the New User: {predicted_learning_style[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5n71ecV0zYN",
        "outputId": "9993648f-75a9-4b8a-c695-0a6f40be3910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 2 Recommendations for User 147:\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import SVD\n",
        "from surprise import accuracy\n",
        "\n",
        "# Let's assume user with ID 147 is the existing user for whom we want to generate recommendations\n",
        "user_id = 147\n",
        "\n",
        "# Get the items the user has already rated\n",
        "rated_items = df[df['id'] == user_id][['Interactive_Videos', 'Mind_Maps', 'Podcasts',\n",
        "                                        'Audiobooks', 'Recorded_Lectures', 'Verbal_Explanations', 'Quizzes',\n",
        "                                        'Interactive_Apps', 'Virtual_Labs', 'Ebooks', 'Study_Guides',\n",
        "                                        'Written_Explanations', 'Online_Articles', 'Practical_Exercises',\n",
        "                                        'Group_Discussions', 'Shared_Notes', 'Visual_Materials',\n",
        "                                        'Interactive_Materials', 'written_Based_materials', 'Hands_Materials',\n",
        "                                        'Collaborative_Materials', 'Auditory_Materials']]\n",
        "\n",
        "# Convert the rated items to a list of tuples (item_id, rating)\n",
        "rated_items = list(rated_items.iloc[0].items())\n",
        "\n",
        "# Filter out items the user has already rated\n",
        "items_to_predict = [item for item, rating in rated_items if pd.isna(rating)]\n",
        "\n",
        "# Generate predictions for the items the user has not yet rated\n",
        "predictions = [model.predict(user_id, item_id) for item_id in items_to_predict]\n",
        "\n",
        "# Sort the predictions by estimated rating in descending order\n",
        "sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
        "\n",
        "# Print the top N recommended items\n",
        "top_n = 2\n",
        "top_recommendations = [(prediction.iid, prediction.est) for prediction in sorted_predictions[:top_n]]\n",
        "\n",
        "print(f\"Top {top_n} Recommendations for User {user_id}:\")\n",
        "for item_id, estimated_rating in top_recommendations:\n",
        "    print(f\"Item ID: {item_id}, Estimated Rating: {estimated_rating}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDHEq_oo04TJ",
        "outputId": "4ccaf79e-89ea-4a6f-d480-a4b20004a31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 Recommendations for User 147:\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions for the items the user has not yet rated\n",
        "predictions = [model.predict(user_id, item_id) for item_id in items_to_predict]\n",
        "\n",
        "# Sort the predictions by estimated rating in descending order\n",
        "sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
        "\n",
        "# Print the top N recommended items\n",
        "top_n = 5\n",
        "top_recommendations = [(prediction.iid, prediction.est) for prediction in sorted_predictions[:top_n]]\n",
        "\n",
        "print(f\"Top {top_n} Recommendations for User {user_id}:\")\n",
        "for item_id, estimated_rating in top_recommendations:\n",
        "    print(f\"Item ID: {item_id}, Estimated Rating: {estimated_rating}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN6muAFlL4nKQOFM5eLyJSU",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
