{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#from caserec.recommenders.hybrid import MMR\n",
        "from sklearn.cluster import KMeans\n",
        "from caserec.recommenders.item_recommendation.userknn import UserKNN\n",
        "from caserec.recommenders.item_recommendation.itemknn import ItemKNN\n",
        "import urllib.parse\n",
        "# Load your dataset\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-31 14:00:07,052 INFO sqlalchemy.engine.Engine SELECT CAST(SERVERPROPERTY('ProductVersion') AS VARCHAR)\n",
            "2024-01-31 14:00:07,053 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
            "2024-01-31 14:00:07,075 INFO sqlalchemy.engine.Engine SELECT schema_name()\n",
            "2024-01-31 14:00:07,075 INFO sqlalchemy.engine.Engine [generated in 0.00089s] ()\n",
            "2024-01-31 14:00:07,144 INFO sqlalchemy.engine.Engine SELECT CAST('test max support' AS NVARCHAR(max))\n",
            "2024-01-31 14:00:07,144 INFO sqlalchemy.engine.Engine [generated in 0.00056s] ()\n",
            "2024-01-31 14:00:07,164 INFO sqlalchemy.engine.Engine SELECT 1 FROM fn_listextendedproperty(default, default, default, default, default, default, default)\n",
            "2024-01-31 14:00:07,164 INFO sqlalchemy.engine.Engine [generated in 0.00052s] ()\n",
            "Connection successful !!!!\n",
            "2024-01-31 14:00:07,204 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
            "2024-01-31 14:00:07,205 INFO sqlalchemy.engine.Engine SELECT id, age, gender, study_field, education_level, employment, study_place FROM import_student;\n",
            "2024-01-31 14:00:07,205 INFO sqlalchemy.engine.Engine [generated in 0.00093s] ()\n",
            "students_df : !!!!!       id  age  gender  study_field  education_level  employment  study_place\n",
            "0   147   20       1            1                1           0            1\n",
            "1   148   31       2            1                2           0            1\n",
            "2   149   36       1            1                2           1            1\n",
            "3   150   25       2            1                2           1            1\n",
            "4   151   34       2            2                1           0            1\n",
            "..  ...  ...     ...          ...              ...         ...          ...\n",
            "68  215   27       2            2                2           0            1\n",
            "69  216   33       2            2                2           1            1\n",
            "70  217   35       2            6                2           0            2\n",
            "71  218   38       1            4                2           1            1\n",
            "72  219   16       1            4                1           1            1\n",
            "\n",
            "[73 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "params = urllib.parse.quote_plus(r'Driver={ODBC Driver 18 for SQL Server};Server=tcp:adaptive-learning-server.database.windows.net,1433;Database=adaptive_learning_db;Uid=superadmin;Pwd=Poorpassword@2024;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;')\n",
        "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
        "engine_azure = create_engine(conn_str,echo=True)\n",
        "\n",
        "connection = engine_azure.connect()\n",
        "print(\"Connection successful !!!!\")\n",
        "\n",
        "students_query = text(\n",
        "    \"SELECT id, age, gender, study_field, education_level, employment, study_place \"\n",
        "    \"FROM import_student;\"\n",
        ")\n",
        "\n",
        "students_result = connection.execute(students_query)\n",
        "\n",
        "# Fetch all the rows and convert them to a Pandas DataFrame\n",
        "students_df = pd.DataFrame(students_result.fetchall(), columns=students_result.keys())\n",
        "print(\"students_df : !!!!! \", students_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-31 13:13:21,778 INFO sqlalchemy.engine.Engine SELECT user_id, item_id, rating FROM rating_materials;\n",
            "2024-01-31 13:13:21,779 INFO sqlalchemy.engine.Engine [generated in 0.00117s] ()\n",
            "ratings_df : !!!!!       user_id  item_id  rating\n",
            "0        147        1       1\n",
            "1        148        1       1\n",
            "2        149        1       1\n",
            "3        150        1       6\n",
            "4        151        1       1\n",
            "..       ...      ...     ...\n",
            "433      215        6       6\n",
            "434      216        6       4\n",
            "435      217        6       6\n",
            "436      218        6       5\n",
            "437      219        6       2\n",
            "\n",
            "[438 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "ratings_query = text(\n",
        "    \"SELECT user_id, item_id, rating \"\n",
        "    \"FROM rating_materials;\"\n",
        ")\n",
        "\n",
        "ratings_result = connection.execute(ratings_query)\n",
        "\n",
        "# Fetch all the rows and convert them to a Pandas DataFrame\n",
        "ratings_df = pd.DataFrame(ratings_result.fetchall(), columns=ratings_result.keys())\n",
        "print(\"ratings_df : !!!!! \", ratings_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_df : !!!!!       user_id  item_id  rating   id  age  gender  study_field  education_level  \\\n",
            "0        147        1       1  147   20       1            1                1   \n",
            "1        147        2       2  147   20       1            1                1   \n",
            "2        147        3       3  147   20       1            1                1   \n",
            "3        147        4       4  147   20       1            1                1   \n",
            "4        147        5       5  147   20       1            1                1   \n",
            "..       ...      ...     ...  ...  ...     ...          ...              ...   \n",
            "433      219        2       5  219   16       1            4                1   \n",
            "434      219        3       4  219   16       1            4                1   \n",
            "435      219        4       1  219   16       1            4                1   \n",
            "436      219        5       3  219   16       1            4                1   \n",
            "437      219        6       2  219   16       1            4                1   \n",
            "\n",
            "     employment  study_place  \n",
            "0             0            1  \n",
            "1             0            1  \n",
            "2             0            1  \n",
            "3             0            1  \n",
            "4             0            1  \n",
            "..          ...          ...  \n",
            "433           1            1  \n",
            "434           1            1  \n",
            "435           1            1  \n",
            "436           1            1  \n",
            "437           1            1  \n",
            "\n",
            "[438 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "merged_df = pd.merge(ratings_df, students_df, how='inner', left_on='user_id', right_on='id')\n",
        "print(\"merged_df : !!!!! \", merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_for_clustering = ['id','age', 'gender', 'study_field', 'education_level', 'employment', 'study_place']\n",
        "user_item_matrix = merged_df.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Apply Clustering Algorithm (e.g., K-means) on Demographic Data\n",
        "# print(\"students_df : !!!!! \", students_df)\n",
        "demographic_data = students_df[features_for_clustering].drop_duplicates().set_index('id')\n",
        "num_clusters = 9  # Adjust the number of clusters as needed\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "user_clusters = kmeans.fit_predict(demographic_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_user_demographics = {\n",
        "    'age': 25,\n",
        "    'gender': '1',\n",
        "    'study_field': '1',\n",
        "    'education_level': '1',\n",
        "    'employment': '1',\n",
        "    'study_place': '1'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        }
      ],
      "source": [
        "num_clusters = 9\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "user_clusters = kmeans.fit_predict(demographic_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Assign the new user to a demographic cluster\n",
        "new_user_cluster = kmeans.predict([list(new_user_demographics.values())])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_members = demographic_data.index[user_clusters == new_user_cluster]\n",
        "\n",
        "# Prepare Input for CaseRecommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_file = 'train_file.dat'  # File to store training data in CaseRecommender format\n",
        "with open(train_file, 'w') as file:\n",
        "    for user in cluster_members:\n",
        "        items_rated = merged_df[merged_df['id'] == user][['item_id', 'rating']].values\n",
        "        for item, rating in items_rated:\n",
        "            file.write(f\"{user}::{item}::{rating}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Case Recommender: Item Recommendation > ItemKNN Algorithm]\n",
            "\n",
            "train data:: 6 users and 6 items (36 interactions) | sparsity:: 0.00%\n",
            "training_time:: 0.001144 sec\n",
            "prediction_time:: 0.000108 sec\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train = ItemKNN(train_file, similarity_metric='cosine', sep='::')\n",
        "train.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Recommended Item: 1\n"
          ]
        }
      ],
      "source": [
        "# Read the train_file and store the data in a dictionary\n",
        "train_file_path = 'train_file.dat'\n",
        "\n",
        "similar_users_ratings = {}\n",
        "with open(train_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        user_id, item_id, rating = map(int, line.strip().split('::'))\n",
        "        if item_id not in similar_users_ratings:\n",
        "            similar_users_ratings[item_id] = []\n",
        "        similar_users_ratings[item_id].append(rating)\n",
        "\n",
        "# Calculate the absolute difference of each item's average rating from 1\n",
        "rating_diff_from_one = {}\n",
        "for item_id, ratings in similar_users_ratings.items():\n",
        "    average_rating = sum(ratings) / len(ratings)\n",
        "    diff_from_one = abs(average_rating - 1)\n",
        "    rating_diff_from_one[item_id] = diff_from_one\n",
        "\n",
        "# Find the item with the minimum absolute difference from 1\n",
        "\n",
        "best_item_id = min(rating_diff_from_one, key=rating_diff_from_one.get)\n",
        "best_rating = rating_diff_from_one[best_item_id]\n",
        "finalrec_query = text(\n",
        "    \"INSERT INTO recommendation_table (id, item_id) \"\n",
        "    \"VALUES (1, :best_item_id);;\"\n",
        ")\n",
        "\n",
        "# Print or use the best item and its adjusted average rating\n",
        "print(f\"Best Recommended Item: {best_item_id}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
