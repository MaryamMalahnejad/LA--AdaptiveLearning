{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFFy3p7iSYPa",
        "outputId": "1b2f8308-afa7-4aa7-e02a-9a64a9fd12cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (1.1.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from scikit-surprise) (1.26.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from scikit-surprise) (1.11.3)\n",
            "Requirement already satisfied: sqlalchemy in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (2.0.25)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from sqlalchemy) (4.8.0)\n",
            "Requirement already satisfied: pymysql in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (1.1.0)\n",
            "Requirement already satisfied: caserecommender in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (1.1.1)\n",
            "Requirement already satisfied: numpy in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from caserecommender) (1.26.0)\n",
            "Requirement already satisfied: scipy in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from caserecommender) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from caserecommender) (1.3.2)\n",
            "Requirement already satisfied: pandas in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from caserecommender) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from pandas->caserecommender) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from pandas->caserecommender) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from pandas->caserecommender) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from scikit-learn->caserecommender) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from scikit-learn->caserecommender) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/mohamedatef/mambaforge/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->caserecommender) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise\n",
        "!pip install sqlalchemy\n",
        "!pip install pymysql\n",
        "!pip install caserecommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GvF3GULZSbB_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-30 22:08:26,125 INFO sqlalchemy.engine.Engine SELECT CAST(SERVERPROPERTY('ProductVersion') AS VARCHAR)\n",
            "2024-01-30 22:08:26,126 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
            "2024-01-30 22:08:26,156 INFO sqlalchemy.engine.Engine SELECT schema_name()\n",
            "2024-01-30 22:08:26,157 INFO sqlalchemy.engine.Engine [generated in 0.00068s] ()\n",
            "2024-01-30 22:08:26,226 INFO sqlalchemy.engine.Engine SELECT CAST('test max support' AS NVARCHAR(max))\n",
            "2024-01-30 22:08:26,227 INFO sqlalchemy.engine.Engine [generated in 0.00134s] ()\n",
            "2024-01-30 22:08:26,248 INFO sqlalchemy.engine.Engine SELECT 1 FROM fn_listextendedproperty(default, default, default, default, default, default, default)\n",
            "2024-01-30 22:08:26,249 INFO sqlalchemy.engine.Engine [generated in 0.00150s] ()\n",
            "Connection successful !!!!\n",
            "2024-01-30 22:08:26,293 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
            "2024-01-30 22:08:26,294 INFO sqlalchemy.engine.Engine SELECT * FROM rating_materials;\n",
            "2024-01-30 22:08:26,294 INFO sqlalchemy.engine.Engine [generated in 0.00079s] ()\n",
            "[Case Recommender: Cross Validation]\n",
            "\n",
            "Database:: ../LA--AdaptiveLearning/u.data \n",
            "Recommender Algorithm:: UserKNN Algorithm | K Folds: 5\n",
            "\n",
            "Eval:: PREC@1: 0.981132 PREC@3: 0.553459 PREC@5: 0.332075 PREC@10: 0.166038 RECALL@1: 0.72327 RECALL@3: 1.0 RECALL@5: 1.0 RECALL@10: 1.0 MAP@1: 0.981132 MAP@3: 0.992138 MAP@5: 0.992138 MAP@10: 0.992138 NDCG@1: 0.981132 NDCG@3: 0.996518 NDCG@5: 0.996518 NDCG@10: 0.996518 \n",
            "Eval:: PREC@1: 1.0 RECALL@1: 0.721154 NDCG@1: 1.0 MAP@1: 1.0 MAP: 0.996795 PREC@3: 0.551282 RECALL@3: 0.990385 NDCG@3: 0.996451 MAP@3: 0.996795 PREC@5: 0.338462 RECALL@5: 1.0 NDCG@5: 0.996451 MAP@5: 0.996795 PREC@10: 0.169231 RECALL@10: 1.0 NDCG@10: 0.996451 MAP@10: 0.996795 \n",
            "Eval:: PREC@1: 1.0 RECALL@1: 0.727564 NDCG@1: 1.0 MAP@1: 1.0 MAP: 1.0 PREC@3: 0.532051 RECALL@3: 0.980769 NDCG@3: 1.0 MAP@3: 1.0 PREC@5: 0.334615 RECALL@5: 1.0 NDCG@5: 1.0 MAP@5: 1.0 PREC@10: 0.167308 RECALL@10: 1.0 NDCG@10: 1.0 MAP@10: 1.0 \n",
            "Eval:: PREC@1: 0.981481 RECALL@1: 0.734568 NDCG@1: 0.981481 MAP@1: 0.981481 MAP: 0.990741 PREC@3: 0.524691 RECALL@3: 0.990741 NDCG@3: 1.0 MAP@3: 0.990741 PREC@5: 0.322222 RECALL@5: 1.0 NDCG@5: 1.0 MAP@5: 0.990741 PREC@10: 0.161111 RECALL@10: 1.0 NDCG@10: 1.0 MAP@10: 0.990741 \n",
            "Eval:: PREC@1: 1.0 RECALL@1: 0.78655 NDCG@1: 1.0 MAP@1: 1.0 MAP: 1.0 PREC@3: 0.497076 RECALL@3: 0.991228 NDCG@3: 1.0 MAP@3: 1.0 PREC@5: 0.305263 RECALL@5: 1.0 NDCG@5: 1.0 MAP@5: 1.0 PREC@10: 0.152632 RECALL@10: 1.0 NDCG@10: 1.0 MAP@10: 1.0 \n",
            "Mean:: PREC@1: 0.992523 RECALL@1: 0.738621 NDCG@1: 0.992523 MAP@1: 0.992523 MAP: 0.995935 PREC@3: 0.531712 RECALL@3: 0.990625 NDCG@3: 0.998594 MAP@3: 0.995935 PREC@5: 0.326527 RECALL@5: 1.000000 NDCG@5: 0.998594 MAP@5: 0.995935 PREC@10: 0.163264 RECALL@10: 1.000000 NDCG@10: 0.998594 MAP@10: 0.995935 \n",
            "STD:: PREC@1: 0.009159 RECALL@1: 0.024399 NDCG@1: 0.009159 MAP@1: 0.009159 MAP: 0.003878 PREC@3: 0.020518 RECALL@3: 0.006090 NDCG@3: 0.001722 MAP@3: 0.003878 PREC@5: 0.011911 RECALL@5: 0.000000 NDCG@5: 0.001722 MAP@5: 0.003878 PREC@10: 0.005955 RECALL@10: 0.000000 NDCG@10: 0.001722 MAP@10: 0.003878 \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# from surprise import Dataset, Reader\n",
        "# from surprise.model_selection import train_test_split\n",
        "# from surprise import SVD  # or any other algorithm you want to use\n",
        "# from surprise import accuracy\n",
        "from caserec.recommenders.item_recommendation.userknn import UserKNN\n",
        "from caserec.utils.cross_validation import CrossValidation\n",
        "from caserec.utils.process_data import ReadFile\n",
        "import urllib.parse\n",
        "# Load your dataset\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "\n",
        "# Load your dataset\n",
        "params = urllib.parse.quote_plus(r'Driver={ODBC Driver 18 for SQL Server};Server=tcp:adaptive-learning-server.database.windows.net,1433;Database=adaptive_learning_db;Uid=superadmin;Pwd=Poorpassword@2024;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;')\n",
        "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
        "engine_azure = create_engine(conn_str,echo=True)\n",
        "\n",
        "connection = engine_azure.connect()\n",
        "print(\"Connection successful !!!!\")\n",
        "\n",
        "# Perform a query to fetch effectivness\n",
        "query = text(\n",
        "    \"SELECT * \"\n",
        "    \"FROM rating_materials;\"\n",
        ")\n",
        "\n",
        "result = connection.execute(query)\n",
        "\n",
        "# Fetch all the rows and convert them to a Pandas DataFrame\n",
        "df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
        "# print(\"!!! df retrieved values:\", df)\n",
        "\n",
        "file_path = '../LA--AdaptiveLearning/u.data'\n",
        "\n",
        "# Convert the DataFrame to the u.data format\n",
        "df[['user_id', 'item_id', 'rating']].to_csv(file_path, sep='\\t', index=False, header=False)\n",
        "\n",
        "# Use CaseRecommender's ReadFile to read the data\n",
        "# data_reader = ReadFile(input_file=file_path, separator='\\t')\n",
        "# data_reader = data_reader.read()\n",
        "\n",
        "recommender = UserKNN()\n",
        "CrossValidation(input_file=file_path, recommender=recommender, dir_folds='../LA--AdaptiveLearning/', header=1, k_folds=5, write_predictions='TRUE').compute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8mV50o4aoqt",
        "outputId": "cccbe282-1867-408c-9958-df3114400964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.5986\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.5986261435477627"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Define the rating scale based on your data\n",
        "reader = Reader(rating_scale=(1, 6))  # Adjust min_rating and max_rating as per your data\n",
        "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.25)  # Adjust test_size as per your preference\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-30 23:04:51,638 INFO sqlalchemy.engine.Engine SELECT CAST(SERVERPROPERTY('ProductVersion') AS VARCHAR)\n",
            "2024-01-30 23:04:51,639 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
            "2024-01-30 23:04:51,664 INFO sqlalchemy.engine.Engine SELECT schema_name()\n",
            "2024-01-30 23:04:51,664 INFO sqlalchemy.engine.Engine [generated in 0.00053s] ()\n",
            "2024-01-30 23:04:51,731 INFO sqlalchemy.engine.Engine SELECT CAST('test max support' AS NVARCHAR(max))\n",
            "2024-01-30 23:04:51,732 INFO sqlalchemy.engine.Engine [generated in 0.00051s] ()\n",
            "2024-01-30 23:04:51,756 INFO sqlalchemy.engine.Engine SELECT 1 FROM fn_listextendedproperty(default, default, default, default, default, default, default)\n",
            "2024-01-30 23:04:51,757 INFO sqlalchemy.engine.Engine [generated in 0.00060s] ()\n",
            "Connection successful !!!!\n",
            "2024-01-30 23:04:51,801 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
            "2024-01-30 23:04:51,801 INFO sqlalchemy.engine.Engine SELECT * FROM rating_materials;\n",
            "2024-01-30 23:04:51,801 INFO sqlalchemy.engine.Engine [generated in 0.00089s] ()\n",
            "df_uim : !!!!!       user_id  item_id  rating\n",
            "0        147        1       1\n",
            "1        148        1       1\n",
            "2        149        1       1\n",
            "3        150        1       6\n",
            "4        151        1       1\n",
            "..       ...      ...     ...\n",
            "433      215        6       6\n",
            "434      216        6       4\n",
            "435      217        6       6\n",
            "436      218        6       5\n",
            "437      219        6       2\n",
            "\n",
            "[438 rows x 3 columns]\n",
            "2024-01-30 23:04:51,829 INFO sqlalchemy.engine.Engine SELECT * FROM user_input_data_integer;\n",
            "2024-01-30 23:04:51,829 INFO sqlalchemy.engine.Engine [generated in 0.00043s] ()\n",
            "df_dd : !!!!!      New_user_id  Age  Gender  Study_Field  Educational_Level  \\\n",
            "0             1   18       2            1                  1   \n",
            "1             2  100       2            3                  3   \n",
            "2             3   14       2            1                  1   \n",
            "3             4   29       2            1                  1   \n",
            "4             7  111       2            1                  1   \n",
            "..          ...  ...     ...          ...                ...   \n",
            "87           71  655       2            1                  1   \n",
            "88           72  999       2            1                  1   \n",
            "89           73    3       2            1                  1   \n",
            "90           74    4       2            1                  1   \n",
            "91           75    4       2            1                  1   \n",
            "\n",
            "    Employment_Status  Preferred_Study_Type  Study_Place  Study_Sound  \\\n",
            "0                   0                     1            1            1   \n",
            "1                   0                     1            1            1   \n",
            "2                   0                     1            1            1   \n",
            "3                   0                     1            1            1   \n",
            "4                   0                     1            1            1   \n",
            "..                ...                   ...          ...          ...   \n",
            "87                  0                     1            1            1   \n",
            "88                  0                     1            1            1   \n",
            "89                  0                     1            1            1   \n",
            "90                  0                     1            1            1   \n",
            "91                  0                     1            1            1   \n",
            "\n",
            "    Studying_Time  Studying_Classes  Support_by_Study_Difficulty  \\\n",
            "0               1                 1                            0   \n",
            "1               3                 1                            0   \n",
            "2               1                 1                            0   \n",
            "3               1                 1                            0   \n",
            "4               1                 1                            0   \n",
            "..            ...               ...                          ...   \n",
            "87              1                 1                            0   \n",
            "88              1                 1                            0   \n",
            "89              1                 1                            0   \n",
            "90              1                 1                            0   \n",
            "91              1                 1                            0   \n",
            "\n",
            "    Likert_Platforms_Effectiveness  Trustworthy_of_AI  \\\n",
            "0                                1                  1   \n",
            "1                                1                  1   \n",
            "2                                1                  1   \n",
            "3                                1                  1   \n",
            "4                                1                  1   \n",
            "..                             ...                ...   \n",
            "87                               1                  1   \n",
            "88                               1                  1   \n",
            "89                               1                  1   \n",
            "90                               1                  1   \n",
            "91                               1                  1   \n",
            "\n",
            "    Relying_on_Recommendation_Paths  \n",
            "0                                 1  \n",
            "1                                 1  \n",
            "2                                 1  \n",
            "3                                 1  \n",
            "4                                 1  \n",
            "..                              ...  \n",
            "87                                1  \n",
            "88                                1  \n",
            "89                                1  \n",
            "90                                1  \n",
            "91                                1  \n",
            "\n",
            "[92 rows x 15 columns]\n",
            "Cluster NEW USER!!! 0\n",
            "Cluster Members!!! Index([ 1,  3,  4, 18, 20, 21, 22, 24, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40,\n",
            "       41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59,\n",
            "       60,  5,  6, 61, 85, 86, 88, 89, 90, 91, 92, 70, 73, 74, 75],\n",
            "      dtype='int64', name='New_user_id')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ZeroDivisionError",
          "evalue": "float division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[31], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# Step 6: Train a Recommendation Model (e.g., UserKNN)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m train \u001b[39m=\u001b[39m UserKNN(train_file, similarity_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m train\u001b[39m.\u001b[39;49mcompute()\n\u001b[1;32m    108\u001b[0m \u001b[39m# Step 7: Make Recommendations for the New User using MMR (Maximal Marginal Relevance)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m# hybrid_recommender = MMR(train_file, train_file, n_recommendations=5, diversity_factor=0.5)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m# hybrid_recommender.compute()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m# print(\"Recommendations for the new user:\")\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m# print(recommendations)\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/caserec/recommenders/item_recommendation/userknn.py:190\u001b[0m, in \u001b[0;36mUserKNN.compute\u001b[0;34m(self, verbose, metrics, verbose_evaluation, as_table, table_sep, n_ranks)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, metrics\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose_evaluation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m    169\u001b[0m             as_table\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, table_sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m, n_ranks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    170\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m    Extends compute method from BaseItemRecommendation. Method to run recommender algorithm\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \n\u001b[1;32m    188\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[39msuper\u001b[39;49m(UserKNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcompute(verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    192\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    193\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtraining_time:: \u001b[39m\u001b[39m%4f\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m timed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_model))\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/caserec/recommenders/item_recommendation/base_item_recommendation.py:188\u001b[0m, in \u001b[0;36mBaseItemRecommendation.compute\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39mMethod to run the recommender algorithm\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m# read files\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_files()\n\u001b[1;32m    190\u001b[0m \u001b[39m# initialize empty ranking (Don't remove: important to Cross Validation)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mranking \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/caserec/recommenders/item_recommendation/base_item_recommendation.py:83\u001b[0m, in \u001b[0;36mBaseItemRecommendation.read_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_files\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     79\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m    Method to initialize recommender algorithm.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_set \u001b[39m=\u001b[39m ReadFile(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_file, sep\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msep, as_binary\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mas_binary)\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_set \u001b[39m=\u001b[39m ReadFile(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_file, sep\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msep)\u001b[39m.\u001b[39mread()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/caserec/utils/process_data.py:94\u001b[0m, in \u001b[0;36mReadFile.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m             list_feedback\u001b[39m.\u001b[39mappend(\u001b[39m1.0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_binary \u001b[39melse\u001b[39;00m value)\n\u001b[1;32m     92\u001b[0m             number_interactions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 94\u001b[0m mean_value \u001b[39m/\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39mfloat\u001b[39;49m(number_interactions)\n\u001b[1;32m     96\u001b[0m list_users \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(list_users))\n\u001b[1;32m     97\u001b[0m list_items \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(list_items))\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "#from caserec.recommenders.hybrid import MMR\n",
        "from caserec.recommenders.item_recommendation.userknn import UserKNN\n",
        "from caserec.recommenders.item_recommendation.itemknn import ItemKNN\n",
        "import urllib.parse\n",
        "# Load your dataset\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "\n",
        "# Load your dataset\n",
        "params = urllib.parse.quote_plus(r'Driver={ODBC Driver 18 for SQL Server};Server=tcp:adaptive-learning-server.database.windows.net,1433;Database=adaptive_learning_db;Uid=superadmin;Pwd=Poorpassword@2024;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;')\n",
        "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
        "engine_azure = create_engine(conn_str,echo=True)\n",
        "\n",
        "connection = engine_azure.connect()\n",
        "print(\"Connection successful !!!!\")\n",
        "\n",
        "# Perform a query to fetch effectivness\n",
        "query_uim = text(\n",
        "    \"SELECT * \"\n",
        "    \"FROM rating_materials;\"\n",
        ")\n",
        "\n",
        "result_uim = connection.execute(query_uim)\n",
        "\n",
        "# Fetch all the rows and convert them to a Pandas DataFrame\n",
        "df_uim = pd.DataFrame(result_uim.fetchall(), columns=result_uim.keys())\n",
        "print(\"df_uim : !!!!! \", df_uim)\n",
        "# print(\"!!! df retrieved values:\", df)\n",
        "\n",
        "# file_path = '../LA--AdaptiveLearning/u.data'\n",
        "# Perform a query to fetch effectivness\n",
        "query_dd = text(\n",
        "    \"SELECT * \"\n",
        "    \"FROM user_input_data_integer;\"\n",
        ")\n",
        "\n",
        "result_dd = connection.execute(query_dd)\n",
        "\n",
        "# Fetch all the rows and convert them to a Pandas DataFrame\n",
        "df_dd = pd.DataFrame(result_dd.fetchall(), columns=result_dd.keys())\n",
        "print(\"df_dd : !!!!! \", df_dd)\n",
        "# # Convert the DataFrame to the u.data format\n",
        "# df[['user_id', 'item_id', 'rating']].to_csv(file_path, sep='\\t', index=False, header=False)\n",
        "# Assuming df is a DataFrame with columns: user_id, item_id, rating, age, gender, study_field, etc.\n",
        "\n",
        "# Step 1: Create User-Item Matrix\n",
        "user_item_matrix = df_uim.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)\n",
        "\n",
        "# Step 2: Apply Clustering Algorithm (e.g., K-means) on Demographic Data\n",
        "demographic_data = df_dd[['New_user_id', 'Age', 'Gender', 'Study_Field', 'Educational_Level', 'Employment_Status',\n",
        "                          'Preferred_Study_Type', 'Study_Place', 'Study_Sound', 'Studying_Time', 'Studying_Classes',\n",
        "                          'Support_by_Study_Difficulty', 'Likert_Platforms_Effectiveness', 'Trustworthy_of_AI',\n",
        "                          'Relying_on_Recommendation_Paths']].drop_duplicates().set_index('New_user_id')\n",
        "# ... preprocess demographic_data if needed ...\n",
        "\n",
        "# ... preprocess demographic_data if needed ...\n",
        "\n",
        "# Assuming 'user_id' is used as an index in both user_item_matrix and demographic_data\n",
        "# Combine user-item interactions with demographic data\n",
        "user_data_matrix = pd.concat([user_item_matrix, demographic_data], axis=1)\n",
        "\n",
        "# Apply clustering to demographic data\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "num_clusters = 5  # Adjust the number of clusters as needed\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "user_clusters = kmeans.fit_predict(demographic_data)\n",
        "\n",
        "# Step 3: Assign a New User to a Cluster (Simulate with a new user's preferences and demographic data)\n",
        "# new_user_preferences = [4, 5, 0, 0, 0, 0]  # Ratings for items, where 0 indicates no interaction\n",
        "new_user_demographics = {\n",
        "    'Age': 25,\n",
        "    'Gender': '1',\n",
        "    'Study_Field': '1',\n",
        "    'Educational_Level': '1',\n",
        "    'Employment_Status': '1',\n",
        "    'Preferred_Study_Type': '1',\n",
        "    'Study_Place': '1',\n",
        "    'Study_Sound': '1',\n",
        "    'Studying_Time': '1',\n",
        "    'Studying_Classes': '1',\n",
        "    'Support_by_Study_Difficulty': '1',\n",
        "    'Likert_Platforms_Effectiveness': '1',\n",
        "    'Trustworthy_of_AI': '1',\n",
        "    'Relying_on_Recommendation_Paths': '1'\n",
        "}\n",
        "# Assign the new user to a demographic cluster\n",
        "new_user_cluster = kmeans.predict([list(new_user_demographics.values())])[0]\n",
        "print(\"Cluster NEW USER!!!\" , new_user_cluster)\n",
        "\n",
        "# Step 4: Get Similar Users from the Same Cluster\n",
        "cluster_members = demographic_data.index[user_clusters == new_user_cluster]\n",
        "print(\"Cluster Members!!!\" , cluster_members)\n",
        "\n",
        "# Step 5: Prepare Input for CaseRecommender\n",
        "train_file = 'train_file.dat'  # File to store training data in CaseRecommender format\n",
        "with open(train_file, 'w') as file:\n",
        "    for user in cluster_members:\n",
        "        items_rated = df[df['user_id'] == user][['item_id', 'rating']].values\n",
        "        for item, rating in items_rated:\n",
        "            file.write(f\"{user}::{item}::{rating}\\n\")\n",
        "\n",
        "# Step 6: Train a Recommendation Model (e.g., UserKNN)\n",
        "train = UserKNN(train_file, similarity_metric='cosine')\n",
        "train.compute()\n",
        "\n",
        "# Step 7: Make Recommendations for the New User using MMR (Maximal Marginal Relevance)\n",
        "# hybrid_recommender = MMR(train_file, train_file, n_recommendations=5, diversity_factor=0.5)\n",
        "# hybrid_recommender.compute()\n",
        "\n",
        "# recommendations = hybrid_recommender.recommend(new_user_preferences, new_user_demographics)\n",
        "\n",
        "# print(\"Recommendations for the new user:\")\n",
        "# print(recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H6SyA-aSud4",
        "outputId": "56c2f0e4-1839-4fbf-9e2f-dcaea63f5ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.5874\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.5874238136082583"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import SVD  # or any other algorithm you want to use\n",
        "\n",
        "# Train your model\n",
        "algo = SVD()  # or any other algorithm\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDm7GR6qSy_U",
        "outputId": "9d9574c6-6c9b-447f-f440-94bd0513f0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.4508\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.4507999945135885"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import prediction_algorithms  # or any other algorithm you want to use\n",
        "\n",
        "# Train your model\n",
        "algo = prediction_algorithms.KNNBasic()  # or any other algorithm\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NttqAgQbS6MF",
        "outputId": "3c4e583f-f8d7-494c-8586-4dabe7e714be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "RMSE: 1.6299\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.6299402661337103"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import prediction_algorithms  # or any other algorithm you want to use\n",
        "\n",
        "# Train your model\n",
        "algo = prediction_algorithms.BaselineOnly()  # or any other algorithm\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYcqbkdOS9bl",
        "outputId": "2e3d08d8-5048-4a53-d80c-2d0e74731012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.4868\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.4868398260101279"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import prediction_algorithms  # or any other algorithm you want to use\n",
        "\n",
        "# Train your model\n",
        "algo = prediction_algorithms.KNNBaseline()  # or any other algorithm\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUrSexrGeFvM",
        "outputId": "a1a147d9-8bf8-44aa-d4b2-a52417b0e507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.6856\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.6856106484719349"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import prediction_algorithms  # or any other algorithm you want to use\n",
        "\n",
        "# Train your model\n",
        "algo = prediction_algorithms.KNNWithMeans()  # or any other algorithm\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nesdyKrieJ3B",
        "outputId": "d15e00d4-d156-4ff0-974b-8119f3667f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 2.2157\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2.215749310031422"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import prediction_algorithms  # or any other algorithm you want to use\n",
        "\n",
        "# Train your model\n",
        "algo = prediction_algorithms.NormalPredictor()  # or any other algorithm\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh56HcIteT79",
        "outputId": "3d3e38e7-e6ea-4325-a7a2-8388c2d74524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.7316\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.7316291982916088"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import prediction_algorithms  # or any other algorithm you want to use\n",
        "\n",
        "# Train your model\n",
        "algo = prediction_algorithms.KNNWithZScore()  # or any other algorithm\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
